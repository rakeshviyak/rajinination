# DO NOT EDIT THIS FILE
# This is a base template. To apply changes to your
# reddit instance, create a "myreddit.update" config
# file, then run 'make ini'. 'make ini' will combine
# this template with the myreddit.update file and create a
# 'myreddit.ini'. ('myreddit.update' is just an example;
# any name will do - e.g., 'foo.update' will create
# 'foo.ini')


#
# r2 - Pylons development environment configuration
#
# The %(here)s variable will be replaced with the parent directory of this file
#
[DEFAULT]

# -- debug and configuation flags --
# global debug flag -- displays pylons stacktrace rather than 500 page on error when true
debug = true
# enables/disables whitespace removal (for development)
template_debug = false
# enables/disables compiled template caching and template file mtime checking
reload_templates = true
# use uncompressed static files (out of /static/js and /static/css)
# rather than compressed files out of /static (for development if true)
uncompressedJS = true
# enable/disable verbose SQL printing 
sqlprinting = false
# enable/disable writing errors as they occur to a rabbit-mq queue
exception_logging = false
# whether to print a "reddit app started" message at start"
log_start = true
# enable/disable logging for amqp/rabbitmq
amqp_logging = false
# emergency measures: makes the site read only
read_only_mode = false
# a modified read only mode used for cache shown during heavy load 503s
heavy_load_mode = false
# directory to write cProfile stats dumps to (disabled if not set)
profile_directory =

# a message placed in the infobar
announcement_message =
# the site's tagline, used in the title and description
short_description = open source is awesome

# -- SECRETS! <-- update these first! --
# global secret
SECRET = abcdefghijklmnopqrstuvwxyz0123456789
# secret for making the modhash
MODSECRET = abcdefghijklmnopqrstuvwxyz0123456789
# secret for /prefs/feeds
FEEDSECRET = abcdefghijklmnopqrstuvwxyz0123456789
# used for authenticating admin API calls w/o cookie
ADMINSECRET = abcdefghijklmnopqrstuvwxyz0123456789

CLOUDSEARCH_SEARCH_API =
CLOUDSEARCH_DOC_API =
CLOUDSEARCH_SUBREDDIT_SEARCH_API =
CLOUDSEARCH_SUBREDDIT_DOC_API =

# -- feature toggles --
disable_ads = false
disable_captcha = false
disable_ratelimit = false
disable_require_admin_otp = false

# -- important settings -- 
# the domain that this app serves itself up as
domain = reddit.local
# the short domain (like redd.it)
shortdomain =
# if you use www for the old-timey feel, put it here
domain_prefix = 
# subdomains that don't need special processing
reserved_subdomains = www, ssl
# the user used for "system" operations and messages
system_user = reddit
# list of admin accounts
admins = reddit
# the default subreddit for submissions
default_sr = reddit.com
# default header image url
default_header_url = reddit.com.header.png

# time for the page cache (for unlogged in users)
page_cache_time = 90
# time for the comment pane cache (for a subset of logged in users, see pages.py:CommentPane)
commentpane_cache_time = 120

# default localization for strings (when using python's locale.format)
locale = C
# default site language (two letter character code)
site_lang = en
lang_override =
# if your webserver is a proxy and on a different instance on the same 10.0.0.0/8 network
# set X-forwarded-for and set this to true
trust_local_proxies = false
# hash for validating HTTP_TRUE_CLIENT_IP_HASH
ip_hash = 
# timezone for storing
timezone = UTC
# timezone for the database
display_timezone = MST
# secret key for accessing /shutdown
shutdown_secret = 12345
# https api endpoint (must be g.domain or a subdomain of g.domain)
https_endpoint =
# name of the cookie to drop with login information
login_cookie = reddit_session
# name of the admin cookie
admin_cookie = reddit_admin
# name of the otp cookie
otp_cookie = reddit_otp
# how to authenticate users. see r2/lib/authentication.py for options
authentication_provider = cookie
# the work factor for bcrypt, increment this every time computers double in
# speed. don't worry, changing this won't break old passwords
bcrypt_work_factor = 12

# fraction of requests to pass into the queue-based usage sampler
usage_sampling = 0.

# account used for default feedback messaging (can be /r/subreddit)
admin_message_acct = reddit


# -- caching options --
# data cache (used for caching Thing objects)
num_mc_clients = 5
memcaches = 127.0.0.1:11211
# caches to use for locking
lockcaches = 127.0.0.1:11211
stalecaches =
# render caches (the second is "remote" and the local is optional but in the same format)
local_rendercache =
rendercaches = 127.0.0.1:11211

# -- permacache options --
# permacache is memcaches -> cassanda -> memcachedb
# memcaches that sit in front of cassandra
permacache_memcaches = 127.0.0.1:11211
# cassandra hosts. one of these will be chosen at random by pycassa
cassandra_seeds = 127.0.0.1:9160
# number of connections to keep open to the cassandra ring
cassandra_pool_size = 5
# read/write consistency levels for Cassandra
cassandra_rcl = ONE
cassandra_wcl = ONE
# name of default connection pool to use when _connection_pool not specified
cassandra_default_pool = main

# -- url cache options --
url_caches = 127.0.0.1:11211
# cassandra hosts. one of these will be chosen at random by pycassa
url_seeds = 


# caches for storing number of times a link is rendered 
incr_cache = udp:localhost:11211
incr_caches = localhost:11211
# recommender cache (depricated)
rec_cache = 127.0.0.1:11211

## -- traffic tracking urls --
# domain to send tracking requests (see scripts/tracker.py)
tracking_domain = reddit.local
# image to render to track pageviews
tracker_url = /static/pixel.png
# images to render to track sponsored links
adtracker_url = /static/pixel.png
# image to render to track the ad frame
adframetracker_url = /static/pixel.png
# open redirector to bounce clicks off of on sponsored links for tracking
clicktracker_url = /static/pixel.png
# url to request to track interaction statistics
uitracker_url = /static/pixel.png
# new pixel
newtracker_url = 

# amqp
amqp_host = localhost:5672
amqp_user = reddit
amqp_pass = reddit
amqp_virtual_host = /

## -- zookeeper --
# optional at the moment
zookeeper_connection_string =
zookeeper_username =
zookeeper_password =

## -- database setup --
# list of all databases named in the subsequent table
databases = main, comment, vote, email, authorize, award, hc, traffic

db_user = reddit
db_pass = password
db_port = 5432
db_pool_size = 3
db_pool_overflow_size = 3

#db name       db         host      user, pass, port, conn, overflow_conn
main_db =      reddit,   127.0.0.1, *,    *,    *,    *,    *
comment_db =   reddit,   127.0.0.1, *,    *,    *,    *,    *
comment2_db =  reddit,   127.0.0.1, *,    *,    *,    *,    *
vote_db =      reddit,   127.0.0.1, *,    *,    *,    *,    *
email_db =     reddit,   127.0.0.1, *,    *,    *,    *,    *
authorize_db = reddit,   127.0.0.1, *,    *,    *,    *,    *
award_db =     reddit,   127.0.0.1, *,    *,    *,    *,    *
hc_db =        reddit,   127.0.0.1, *,    *,    *,    *,    *
traffic_db =   reddit,   127.0.0.1, *,    *,    *,    *,    *

hardcache_categories = *:hc:hc

# this setting will prefix all of the table names
db_app_name = reddit
# are we allowed to create tables?
db_create_tables = True
# are we allowed to write at all?
disallow_db_writes = False

type_db = main
rel_type_db = main
hardcache_db = main

# definitions of what each table is (probably shouldn't change in .update files)
# things require no extra info. relation is followed by the names of the related tables
db_table_link = thing
db_table_account = thing
db_table_message = thing
db_table_savehide = relation, account, link
db_table_click = relation, account, link
db_table_comment = thing
db_table_subreddit = thing
db_table_srmember = relation, subreddit, account
db_table_friend = relation, account, account
db_table_vote_account_link = relation, account, link
db_table_vote_account_comment = relation, account, comment
db_table_inbox_account_comment = relation, account, comment
db_table_inbox_account_message = relation, account, message
db_table_moderatorinbox = relation, subreddit, message
db_table_report_account_link = relation, account, link
db_table_report_account_comment = relation, account, comment
db_table_report_account_message = relation, account, message
db_table_report_account_subreddit = relation, account, subreddit
db_table_award = thing
db_table_trophy = relation, account, award
db_table_jury_account_link = relation, account, link
db_table_ad = thing
db_table_adsr = relation, ad, subreddit
db_table_flair = relation, subreddit, account
db_table_promocampaign = thing

# which servers to find each table on (likely to change in .update files)
# first server listed is assumed to be the master, all others are read-only slaves
# additionally, a "!avoid_master" flag may be added to specify that reads should use the slaves
db_servers_link = main, main
db_servers_account = main
db_servers_message = main
db_servers_savehide = main
db_servers_click = main
db_servers_comment = comment
db_servers_subreddit = comment
db_servers_srmember = comment
db_servers_friend = comment
db_servers_vote_account_link = vote
db_servers_vote_account_comment = vote
db_servers_inbox_account_comment = main
db_servers_inbox_account_message = main
db_servers_moderatorinbox = main
db_servers_report_account_link = main
db_servers_report_account_comment = comment
db_servers_report_account_message = main
db_servers_report_account_subreddit = main
db_servers_award = award
db_servers_trophy = award
db_servers_jury_account_link = main
db_servers_ad = main
db_servers_adsr = main
db_servers_flair = main
db_servers_promocampaign = main


## -- traffic analytics --
# google analytics token
googleanalytics = 
# machine to get traffic metrics from
traffic_url = http://localhost:8010/tracker/pickle/
# secret used for talking to the traffic machine
tracking_secret = abcdefghijklmnopqrstuvwxyz0123456789


## -- Self-service sponsored link stuff --
# (secure) payment domain
payment_domain = https://pay.reddit.local/
ad_domain = http://reddit.local
allowed_pay_countries = United States, United Kingdom, Canada
sponsors =

# authorize.net credentials (blank authorizenetapi to disable)
authorizenetapi =
# authorizenetapi = https://api.authorize.net/xml/v1/request.api
authorizenetname = 
authorizenetkey = 

min_promote_bid = 20
max_promote_bid = 9999
min_promote_future = 2

# -- spreadshirt --
spreadshirt_url = 
spreadshirt_vendor_id =
spreadshirt_min_font =  42
spreadshirt_max_width = 620
spreadshirt_test_font = 


###
# Other magic settings
###

# list of cnames allowed to render as reddit.com without a frame
authorized_cnames = 

# -- query cache settings --
num_query_queue_workers = 5
query_queue_worker = http://cslowe.local:8000
enable_doquery = True
use_query_cache = True
write_query_queue = True
querycache_prune_chance = 0.05

# -- stylesheet editor --
# disable custom stylesheets
css_killswitch = False
# list of "trusted" domains that can be referenced in url()
allowed_css_linked_domains = static.reddit.com, www.reddit.com, reallystatic.reddit.com
# max number of uploaded images per subreddit
max_sr_images = 50
# default stylesheet and it's rtl version
stylesheet = reddit.css
stylesheet_rtl = reddit-rtl.css
# location of the static directory
static_path = /static/
# if set, these are the domains used for static files served over http and https
# if not set, no domain will be specified
static_domain =
static_secure_domain =
# if this is true, append .gz to CSS and JS files served from the static domain
# this is for hosts that don't do on-the-fly gzipping (e.g. s3)
static_pre_gzipped = false
static_secure_pre_gzipped = false
# which s3 bucket to place subreddit styles on (when empty, stylesheets will be served
# from the local database instead.
static_stylesheet_bucket =

#  -- translator UI -- 
# enable/disable access to the translation UI in /admin/i18n
translator = true
# reddit runs the translator UI on a different instance with a
# password to login.  These settings are used when generating messages
# to translators to tell them their credentials
translator_username =
translator_password =

# subreddit used for DMCA takedowns
takedown_sr = _takedowns
# png compressor
png_optimizer = /usr/bin/env optipng
# jpeg compressor
jpeg_optimizer =

# Just a list of words. Used by errlog.py to make up names for new errors.
words_file = /usr/dict/words

# -- media stuff --
# user agent for the scraper
useragent = Mozilla/5.0 (compatible; redditbot/1.0; +http://www.reddit.com/feedback)

# The storage method to use for media
# Options:
#      s3 - Uses Amazon S3 to upload media to buckets
media_store = s3

# your s3 credentials
S3KEY_ID = 
S3SECRET_KEY = 

# This bucket is used for old media, new installs may leave this blank
s3_old_thumb_bucket = 

# May be one bucket, or many buckets seperated by commas
s3_media_buckets = 

# Store direct urls for images, rather than buckets
# For the bucket mybucket with the image helloworld.jpg the stored url would be:
#   true:  http://s3.amazonaws.com/mybucket/helloworld.jpg
#   false: http://mybucket/helloworld.jpg
s3_media_direct = true

media_domain = localhost
# Embedly API Key
embedly_api_key =

# -- limits --
# rate limiter duration (minutes)
RATELIMIT = 10
# minimum display karma
MIN_UP_KARMA = 1
MIN_RATE_LIMIT_KARMA = 10
MIN_RATE_LIMIT_COMMENT_KARMA = 1
QUOTA_THRESHOLD = 5
# Links and comments older than this many days qualify for historic preservation
REPLY_AGE_LIMIT = 180
# Links and comments older than this many days can't be voted on
VOTE_AGE_LIMIT = 180
# minimum age, in days, of an account to be eligible to create a community
min_membership_create_community = 30
# the maximum life of an admin cookie (seconds)
ADMIN_COOKIE_TTL = 32400
# the maximum amount of idle time for an admin cookie (seconds)
ADMIN_COOKIE_MAX_IDLE = 900
# the maximum life of an otp cookie
OTP_COOKIE_TTL = 604800

# time in days
MODWINDOW = 2
HOT_PAGE_AGE = 1000

# -- display options --
# how long to consider links eligible for the rising page
rising_period = 12 hours
# max number of comments (default)
num_comments = 100
# max number of comments (non-gold)
max_comments = 500
# max number of comments (gold)
max_comments_gold = 2500
# list of reddits to auto-subscribe users to
automatic_reddits = 
# special reddit that only reddit gold subscribers can use
lounge_reddit =
# cutoff number of reddits to show unsubscribed users
num_default_reddits = 10
# how deep do we go into the top listing when fetching /random
num_serendipity = 250
sr_dropdown_threshold = 15

# Conflate visits to a comment page that happen within this many
# seconds of each other
comment_visits_period = 600

#user-agents to rate-limit
agents = 
# subreddit ratelimits
sr_banned_quota = 10000
sr_moderator_quota = 10000
sr_contributor_quota = 10000
sr_wikibanned_quota = 10000
sr_wikicontributor_quota = 10000
sr_quota_time = 7200

# -- email --
# smtp server
smtp_server = localhost
# delay before allowing a link to be shared
new_link_share_delay = 30 seconds
# alerter emails
nerds_email = nerds@reddit.com
# share reply email
share_reply = noreply@reddit.com
# feedback email 
feedback_email = reddit@gmail.com

# Special case sensitive domains
case_sensitive_domains = i.imgur.com, youtube.com

# Number of days to keep recent wiki revisions for
wiki_keep_recent_days = 7

# Max number of bytes for wiki pages
wiki_max_page_length_bytes = 262144

# Max wiki page name length
wiki_max_page_name_length = 128

# Max number of separators in a wiki page name
wiki_max_page_separators = 3

# Disable wiki editing and viewing for everyone except admins
wiki_disabled = false

# Location (directory) for temp files for diff3 merging
# Empty will use python default for temp files
#   Pro tip: Use /dev/shm for in-memory diff3
diff3_temp_location =

[server:main]
use = egg:Paste#http
host = 0.0.0.0
port = %(http_port)s

[app:main]
use = egg:r2
cache_dir = %(here)s/data
beaker.session_key = r2
beaker.session_secret = somesecret
#lang = en

# WARNING: *THE LINE BELOW MUST BE UNCOMMENTED ON A PRODUCTION ENVIRONMENT*
# Debug mode will enable the interactive debugging tool, allowing ANYONE to
# execute malicious code after an exception is raised.
#set debug = false

# the following configuration section makes up the "live" config. if zookeeper
# is enabled, then this configuration will be found by the app in zookeeper. to
# write it to zookeeper, use the writer script: scripts/write_live_config.
[live_config]
# make frontpage 100% dart
frontpage_dart = false
# links that get their own infrastructure (comma-delimited list of id36s)
fastlane_links =
# spotlight links for subreddit discovery
sr_discovery_links = 
# probability of the subreddit suggester showing up in the spotlight box
# for users that have at some point edited their subscriptions:
spotlight_interest_sub_p = .05
# and for users that have not ever subscribed:
spotlight_interest_nosub_p = .1
